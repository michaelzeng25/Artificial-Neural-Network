{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# work with black and shite images of size 28x28=784 pixels. \n",
    "# try to predict what number is in the image based on the image data \n",
    "# in the form of an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1, read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets(\"/tmp/data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow.examples.tutorials.mnist.input_data' from '/Users/michaelzeng/anaconda3/lib/python3.6/site-packages/tensorflow/examples/tutorials/mnist/input_data.py'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "module"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x1182922b0>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x1c37e2fef0>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x1c37e2feb8>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet at 0x1182922b0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist.train.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ndarray.reshape>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "builtin_function_or_method"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist.train.images.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take a look at one of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c8c4c24e0>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKMMvFWX4paIMv1SU4ZeK+n/WC3KuvgBc8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c237f79b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[1].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2, create the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorflow graph input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1=256# 256 neurons is just a common number for each layer\n",
    "n_hidden_2=256\n",
    "n_input=784 # 28x28 which is the size of the picture\n",
    "n_classes=10 # total classes\n",
    "# x and y will be use in function 'add' later\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create 2 dictionaries contained the weight and bias objects for the model\n",
    "weights={\n",
    "    'w1':tf.Variable(tf.random_normal([n_input,n_hidden_1])),\n",
    "    'w2':tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden_2,n_classes]))\n",
    "}\n",
    "\n",
    "biases={\n",
    "    'b1':tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the layers\n",
    "# relu= an activation function, which is a simple rectifier function which\n",
    "# either returns x or zero\n",
    "# use linear activation with matrix mul here\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    layer_1=tf.add(tf.matmul(x,weights['w1']), biases['b1'])\n",
    "    # RELU(x * w + b) -> f(x)=max(0,x)\n",
    "    layer_1=tf.nn.relu(layer_1)\n",
    "    \n",
    "    layer_2=tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2=tf.nn.relu(layer_2)\n",
    "    \n",
    "    out_layer=tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define loss and optimizer, and init.. the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=multilayer_perceptron(x, weights, biases)\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the variables for cost and optimization functions\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32),\n",
       " array([0, 8, 7, 4, 1, 3, 3, 3, 6, 9, 6, 4, 0, 5, 7, 7, 9, 5, 5, 1, 9, 7, 4,\n",
       "        7, 5, 4, 0, 7, 0, 8, 6, 1, 6, 0, 4, 9, 3, 6, 4, 9, 9, 6, 0, 1, 0, 5,\n",
       "        3, 7, 9, 4, 2, 6, 3, 3, 8, 5, 3, 9, 0, 1, 0, 5, 9, 2, 2, 7, 1, 6, 8,\n",
       "        1, 3, 8, 1, 4, 1, 0, 7, 7, 2, 1, 1, 7, 5, 9, 5, 4, 9, 8, 1, 0, 6, 4,\n",
       "        7, 2, 2, 0, 4, 8, 0, 8], dtype=uint8))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " mnist.train.next_batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "n_samples = mnist.train.num_examples\n",
    "\n",
    "#init must place before sess\n",
    "init=tf.initialize_all_variables()\n",
    "\n",
    "# lunch the session\n",
    "sess=tf.InteractiveSession()\n",
    "# intilialize all the variables\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost=168.0663\n",
      "Epoch: 2 cost=41.7244\n",
      "Epoch: 3 cost=26.0072\n",
      "Epoch: 4 cost=17.8791\n",
      "Epoch: 5 cost=12.8418\n",
      "Epoch: 6 cost=9.4039\n",
      "Epoch: 7 cost=7.0934\n",
      "Epoch: 8 cost=5.3441\n",
      "Epoch: 9 cost=3.8813\n",
      "Epoch: 10 cost=2.9123\n",
      "Epoch: 11 cost=2.1522\n",
      "Epoch: 12 cost=1.6293\n",
      "Epoch: 13 cost=1.3735\n",
      "Epoch: 14 cost=0.9683\n",
      "Epoch: 15 cost=0.8609\n",
      "\n",
      "\n",
      "Model has completed 15 Epochs of Training\n"
     ]
    }
   ],
   "source": [
    "# Training Epochs\n",
    "# Essentially the max amount of loops possible before we stop\n",
    "# May stop earlier if cost/loss limit was set\n",
    "for epoch in range(training_epochs):\n",
    "\n",
    "    # Start with cost = 0.0\n",
    "    avg_cost = 0.0\n",
    "\n",
    "    # Convert total number of batches to integer\n",
    "    total_batch = int(n_samples/batch_size)\n",
    "\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "\n",
    "        # Grab the next batch of training data and labels\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        # Feed dictionary for optimization and loss value\n",
    "        # Returns a tuple, but we only need 'c' the cost\n",
    "        # So we set an underscore as a \"throwaway\"\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        # Compute average loss\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print(\"Epoch: {} cost={:.4f}\".format(epoch+1,avg_cost))\n",
    "print('\\n')\n",
    "print(\"Model has completed {} Epochs of Training\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a check of predictions == y_test\n",
    "correct_predictions = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_3:0' shape=() dtype=bool>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In order to get a numerical value for our predictions we will \n",
    "#need to use tf.cast to cast the Tensor of booleans back into a Tensor \n",
    "#of Floating point values in order to take the mean of it.\n",
    "correct_predictions = tf.cast(correct_predictions, \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9489\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 95% of the chance to correctly identify the number in the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
